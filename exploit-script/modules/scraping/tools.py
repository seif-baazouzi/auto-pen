import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import log

from utils.form import getForm, isUniqForm
from utils.url import Url, host, isUniqUrl, validPath

###########################################################################
###########################################################################

def collectUrlsAndForms(url, cookies, urlsList=[], formsList=[]):
  if isUniqUrl(url, urlsList):
    log.item(f"Url: {url}")
    urlsList.append(url)
  else:
    return urlsList, formsList

  if url.sample().find("logout") != -1:
    return urlsList, formsList

  try:
    reqs = requests.get(url, cookies=cookies)
    soup = BeautifulSoup(reqs.text, "html.parser")
  except:
    return urlsList, formsList

  urlHost = host(url)
  for link in soup.find_all("a"):
    href = link.get("href")

    if not href or not validPath(urlHost, href):
      continue
    
    newUrl = Url(urljoin(url.sample(), href))
    collectUrlsAndForms(newUrl, cookies, urlsList, formsList)

  for form in soup.find_all("form"):
    form = getForm(url, form)
    if form and isUniqForm(form, formsList):
      log.item(f"Form: {form}")
      formsList.append(form)

  return urlsList, formsList

###########################################################################
###########################################################################

def gobusterScan(url):
  cmd = f"gobuster dir -r -t 10 -w lists/common.txt -o tmp/gobuster -u '{url}' -x html,php,jsp,aspx,asp,htm"
  log.cmd(cmd)
  os.system(cmd)

  with open("tmp/gobuster", "r") as f:
    pathsList = [ path.split()[0][1:] for path in f.readlines() if path != "" ]
    f.close()
  
  return pathsList

###########################################################################
###########################################################################

def scraping(url, cookies, gobusterPaths):
  urls, forms = [], []
  for path in gobusterPaths:
    currentUrl = Url(urljoin(url, path))
    urls, forms = collectUrlsAndForms(currentUrl, cookies, urls, forms)
  
  return collectUrlsAndForms(Url(url), cookies, urls, forms)  

###########################################################################
###########################################################################

def generate404Page(url):
  return Url(url, is404=True)
