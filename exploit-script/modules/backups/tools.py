import requests
from urllib.parse import urljoin

from utils.parselist import parseList
from utils.threadingloop import threadingLoop

###########################################################################
###########################################################################

backupsFiles = [
  "backup.tar.bz2",
  "backup.tar.gz",
  "backup.bz2",
  "backup.rar",
  "backup.gz",
  "backup.tar",
  "backup.tbz2",
  "backup.tgz",
  "backup.zip",
  "backup.Z",
  "backup.7z",
  "backup.deb",
  "backup.tar.xz",
  "backup.tar.zst",
]

###########################################################################
###########################################################################

def filterDynamicRoutes(urls):
  filteredUrls = []
  for url in urls:
    lastIndex = len(url.path.pathList) - 1
    if lastIndex not in url.path.paramsIndexes:
      filteredUrls.append(url)
    
  return filteredUrls

###########################################################################
###########################################################################

def generateUrlsList(urls):
  pathsList = []
  urls = filterDynamicRoutes(urls[:-1])

  for url in urls:
    newPath = ""
    pathParts = url.parsed.path.split("/")
    for index in range(len(pathParts)-1):
      newPath += f"{pathParts[index]}/"
      if newPath not in pathsList:
        pathsList.append(newPath)

  urlsList = []
  urlSample = urls[0].sample()
  
  for path in pathsList:
    url = urljoin(urlSample, path)
    urlsList.append(url)

  return urlsList

###########################################################################
###########################################################################

def generateFilesList():
  with open("lists/common.txt", "r") as f:
    fileNames = [ fileName.strip() for fileName in f.readlines() if fileName ]
    f.close()

  for fileName in fileNames:
    yield parseList("backups.txt", fileName)

###########################################################################
###########################################################################

def checkBackupsFiles(fileName, url, resutls, findBackupCallBack):
  url = urljoin(url, fileName)
  res = requests.get(url)
  if res.status_code == 200:
    findBackupCallBack(url, resutls)

###########################################################################
###########################################################################

def findBackups(urls, findBackupCallBack):
  resutls = []
  for url in urls:
    threadingLoop(checkBackupsFiles, backupsFiles, (url, resutls, findBackupCallBack))    
    for filesList in generateFilesList():
      threadingLoop(checkBackupsFiles, filesList, (url, resutls, findBackupCallBack))    

  return resutls
